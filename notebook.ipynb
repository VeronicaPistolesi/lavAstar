{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Hypothesis: A* finds always the 'ShortBest' path!\n",
    "\n",
    "Let's see, if this is true ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importations\n",
    "import gym\n",
    "import minihack\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from algorithms import *\n",
    "from classes import *\n",
    "from utils import *\n",
    "from env_levels import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Static Environment\n",
    "\n",
    "We've developed a custom environment using the **Minihack level editor** to gain precise control over our work. The environment we're working on is a 15x15 **fully observable maze**, where the agent navigates through the grid while avoiding hazardous **lava pools**.\n",
    "\n",
    "The agent starts in the *top left corner* and needs to find the stairs in the *bottom right corner* while avoiding lava pools. \n",
    "\n",
    "Inside *env_levels.py* there is the *'.des-file'*:\n",
    "\n",
    "* Agent: '@'\n",
    "* Target: '>'\n",
    "* Floor tile: '.'\n",
    "* Walls: '-' and '|'\n",
    "* Lava pools: 'L'\n",
    "\n",
    "> As part of our exploration, we're committed to introducing and navigating through **various levels of complexity**. This initiative allows us to test and implement different search algorithms tailored to the evolving challenges presented by each level. This dynamic approach not only showcases the adaptability of our agent but also facilitates a comprehensive evaluation of its problem-solving capabilities across diverse scenarios.\n",
    "\n",
    "For now, we: \n",
    "* initialize the specific map configuration\n",
    "* set a random seed for reproducibility\n",
    "* reset the environment to get the initial observation\n",
    "* render the environment for visual representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_lv1 = gym.make(\n",
    "    \"MiniHack-Navigation-Custom-v0\",\n",
    "    des_file=des_file_static_lv1,\n",
    "    #max_episode_steps=50,\n",
    "    observation_keys =(\"chars\", \"colors\", \"specials\", \"pixel\")\n",
    ")\n",
    "\n",
    "env_lv1.seed(42)\n",
    "obs_lv1 = env_lv1.reset() #each reset generates a new environment instance\n",
    "env_lv1.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(obs_lv1['pixel'][45:290, 0:250]) #Plots directly from minihack generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = obs_lv1['pixel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_case1 = []\n",
    "comparison_case2 = []\n",
    "comparison_case3 = []\n",
    "algorithms = ['Breadth First Search (UA)', 'Uniform Cost Search (UA)', 'A* (IA)', 'Greedy Best First Search (IA)']\n",
    "time_case1 = []\n",
    "path_case1 = []\n",
    "time_case2 = []\n",
    "path_case2 = []\n",
    "time_case3 = []\n",
    "path_case3 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A GridWorld Problem\n",
    "\n",
    "To streamline the implementation of search algorithms in our agent, we've established a problem definition encapsulated within a class. Specifically, we've conceptualized our problem using a **GridWorldProblem class**. This class serves as a foundation for formulating the problem in a way that aligns with the principles of graph search algorithms.\n",
    "\n",
    "As these search algorithms operate on graphs, we visualize the **corresponding graph of the agent's environment**. This graph effectively represents the navigable nodes within the maze, and we highlight the coordinates of each node for clarity. The edges connecting these states within the graph are assigned a uniform cost of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case we will consider the _chars_ representation, a multi-dimensional array containing the ASCII encoding of the characters. More specifically:\n",
    "\n",
    "* Agent: ASCII 64\n",
    "* Stairs: ASCII 62\n",
    "* Walls: ASCII\n",
    "* Lava: ASCII 125\n",
    "\n",
    "> To ensure an accurate and meaningful representation of the maze environment within the graph, we undertake a crucial **preprocessing step**. This step involves meticulous manipulation of the Minihack matrix, allowing us to narrow our focus exclusively to the observable aspects of the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_map_lv1 = process_matrix(obs_lv1['chars'])\n",
    "print(game_map_lv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_matrix(obs_lv1['colors'])\n",
    "# 6 -> blue\n",
    "# 1 -> red\n",
    "game_map_lv1_colors = process_matrix(obs_lv1['colors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_problem1 = GridWorldProblem(game_map_lv1, find_state_coord(game_map_lv1, ord('@')), find_state_coord(game_map_lv1, ord('>')), game_map_lv1_colors)\n",
    "\n",
    "print(\"Initial state:\", grid_problem1.initial_state)\n",
    "print(\"Goal state:\", grid_problem1.goal_state)\n",
    "\n",
    "basic_graph = create_basic_graph(grid_problem1, grid_problem1.initial_state)\n",
    "\n",
    "plot_graph(basic_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u> CASE 1 </u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uninformed Agent (Breadth-First-Search)\n",
    "\n",
    "Our uninformed agent employs the Breadth-First Search (BFS) algorithm to navigate through the grid world problem.\n",
    "\n",
    "* Red Nodes: Lava pools.\n",
    "* Green Nodes: Nodes visited by the agent\n",
    "* Blue Node: Initial position of the agent\n",
    "\n",
    "> This visualization provides a clear depiction of the agent's exploration process, distinguishing between hazardous areas (lava pools), traversed paths, and the starting point of the agent. The Breadth-First Search algorithm ensures a systematic exploration of the grid, contributing to efficient pathfinding in our maze-like environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uninformed_agent = UninformedSearchAgent(grid_problem1) # Instantiate an Uninformed Search Agent\n",
    "\n",
    "solution_path = uninformed_agent.search(breadth_first_search) # Perform uniformed search with the Breadth-First Search\n",
    "\n",
    "time_case1.append(uninformed_agent.execution_time())\n",
    "path_case1.append(len(solution_path))\n",
    "\n",
    "print(f'Time: {uninformed_agent.execution_time()} seconds')\n",
    "print(f'The found path is long {len(solution_path)}.')\n",
    "\n",
    "# Highlight the explored nodes in green\n",
    "basic_graph = create_basic_graph(grid_problem1, grid_problem1.initial_state)\n",
    "explored_graph = highlight_explored_nodes(basic_graph, solution_path)\n",
    "\n",
    "plot_graph(explored_graph) # Plot the graph with both basic and explored nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT\n",
    "actions = actions_from_path(find_state_coord(game_map_lv1, ord('@')), solution_path)\n",
    "\n",
    "import IPython.display as display\n",
    "\n",
    "image = plt.imshow(game[25:300, :475])\n",
    "for action in actions:\n",
    "    s, _, _, _ = env_lv1.step(action)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    image.set_data(s['pixel'][25:300, :475])\n",
    "    time.sleep(0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uninformed Agent (Dijkstra's Algorithm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uninformed_agent = UninformedSearchAgent(grid_problem1)\n",
    "solution_path, node_distances = uninformed_agent.search(uniform_cost_search)\n",
    "\n",
    "time_case1.append(uninformed_agent.execution_time())\n",
    "path_case1.append(len(solution_path))\n",
    "\n",
    "print(f'Time: {uninformed_agent.execution_time()} seconds')\n",
    "print(f'The taken path has the length {len(solution_path)} (steps).')\n",
    "\n",
    "# Highlight the explored nodes in green\n",
    "basic_graph = create_basic_graph(grid_problem1, grid_problem1.initial_state)\n",
    "explored_graph = highlight_explored_nodes(basic_graph, solution_path)\n",
    "\n",
    "# Plot the graph with both basic and explored nodes\n",
    "plot_graph_distances(explored_graph, node_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informed Agent (A*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "informed_agent = InformedSearchAgent(grid_problem1)\n",
    "solution_path, explored_nodes_paths, node_distances = informed_agent.search(astar_search, manhattan_distance)\n",
    "\n",
    "time_case1.append(informed_agent.execution_time())\n",
    "path_case1.append(len(solution_path))\n",
    "\n",
    "print(f'Time: {informed_agent.execution_time()} seconds')\n",
    "print(f\"The found path is long {len(solution_path)}\")\n",
    "\n",
    "# Highlight the explored nodes in green\n",
    "basic_graph = create_basic_graph(grid_problem1, grid_problem1.initial_state)\n",
    "explored_graph = highlight_explored_nodes(basic_graph, solution_path)\n",
    "\n",
    "\n",
    "# Plot the graph with both basic and explored nodes\n",
    "plot_graph_distances(explored_graph, node_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informed Agent (Greedy Best First Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "informed_agent = InformedSearchAgent(grid_problem1)\n",
    "solution_path, explored_nodes_paths, node_distances = informed_agent.search(greedy_best_first_search, manhattan_distance)\n",
    "\n",
    "time_case1.append(informed_agent.execution_time())\n",
    "path_case1.append(len(solution_path))\n",
    "\n",
    "print(f'Time: {informed_agent.execution_time()} seconds')\n",
    "print(f\"The found path is long {len(solution_path)}\")\n",
    "\n",
    "# Highlight the explored nodes in green\n",
    "basic_graph = create_basic_graph(grid_problem1, grid_problem1.initial_state)\n",
    "explored_graph = highlight_explored_nodes(basic_graph, solution_path)\n",
    "\n",
    "# Plot the graph with both basic and explored nodes\n",
    "plot_graph_distances(explored_graph, node_distances)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
